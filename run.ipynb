{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd4311e7",
   "metadata": {},
   "source": [
    "# Speaker Verification Inference\n",
    "This notebook demonstrates how to perform direct inference for speaker verification using the ModelScope pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf4e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6458bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 05:17:16,203 - modelscope - WARNING - Model revision not specified, use revision: v1.2.2\n",
      "2025-05-08 05:17:16,573 - modelscope - INFO - initiate model from /home/maojia/.cache/modelscope/hub/damo/speech_xvector_sv-zh-cn-cnceleb-16k-spk3465-pytorch\n",
      "2025-05-08 05:17:16,574 - modelscope - INFO - initiate model from location /home/maojia/.cache/modelscope/hub/damo/speech_xvector_sv-zh-cn-cnceleb-16k-spk3465-pytorch.\n",
      "2025-05-08 05:17:16,575 - modelscope - INFO - initialize model from /home/maojia/.cache/modelscope/hub/damo/speech_xvector_sv-zh-cn-cnceleb-16k-spk3465-pytorch\n",
      "2025-05-08 05:17:16,577 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2025-05-08 05:17:16,577 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2025-05-08 05:17:16,578 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/home/maojia/.cache/modelscope/hub/damo/speech_xvector_sv-zh-cn-cnceleb-16k-spk3465-pytorch'}. trying to build by task and model information.\n",
      "2025-05-08 05:17:16,578 - modelscope - WARNING - No preprocessor key ('generic-sv', 'speaker-verification') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2025-05-08 05:17:16,803 - modelscope - INFO - Speaker Verification Processing: ('https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_enroll.wav', 'https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_same.wav') ...\n",
      "2025-05-08 05:17:20,467 - modelscope - INFO - Speaker Verification Processing: ('https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_enroll.wav', 'https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_different.wav') ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same speaker similarity: [0.8540488358969999, 0.14595116410300013]\n",
      "Different speaker similarity: [0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the speaker verification pipeline\n",
    "inference_sv_pipeline = pipeline(\n",
    "    task=Tasks.speaker_verification,\n",
    "    model=\"damo/speech_xvector_sv-zh-cn-cnceleb-16k-spk3465-pytorch\",\n",
    ")\n",
    "\n",
    "# Inference: same speaker\n",
    "rec_result_same = inference_sv_pipeline(\n",
    "    audio_in=(\n",
    "        \"https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_enroll.wav\",\n",
    "        \"https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_same.wav\",\n",
    "    )\n",
    ")\n",
    "print(\"Same speaker similarity:\", rec_result_same[\"scores\"])\n",
    "\n",
    "# Inference: different speaker\n",
    "rec_result_diff = inference_sv_pipeline(\n",
    "    audio_in=(\n",
    "        \"https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_enroll.wav\",\n",
    "        \"https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_different.wav\",\n",
    "    )\n",
    ")\n",
    "print(\"Different speaker similarity:\", rec_result_diff[\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f16ec446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 05:18:03,530 - modelscope - INFO - Speaker Verification Processing: https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_enroll.wav ...\n",
      "2025-05-08 05:18:07,414 - modelscope - INFO - Speaker Verification Processing: https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_same.wav ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.40488358969999\n"
     ]
    }
   ],
   "source": [
    "enroll = inference_sv_pipeline(audio_in='https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_enroll.wav')[\"spk_embedding\"]\n",
    "\n",
    "same = inference_sv_pipeline(audio_in='https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/sv_example_same.wav')[\"spk_embedding\"]\n",
    "\n",
    "import numpy as np\n",
    "# 对相同的说话人计算余弦相似度\n",
    "sv_threshold=0.9465\n",
    "same_cos=np.sum(enroll*same)/(np.linalg.norm(enroll)*np.linalg.norm(same))\n",
    "same_cos=max(same_cos - sv_threshold, 0.0) / (1.0 - sv_threshold) * 100.0\n",
    "print(same_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d1921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ['Same', 'Different'],\n",
       " 'scores': [0.8540488358969999, 0.14595116410300013]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_result_same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ff6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 05:03:29,525 - modelscope - INFO - Use user-specified model revision: v1.0.0\n",
      "Downloading: 100%|██████████| 407/407 [00:00<00:00, 2.92MB/s]\n",
      "Downloading: 100%|██████████| 143k/143k [00:00<00:00, 235kB/s]\n",
      "Downloading: 100%|██████████| 123k/123k [00:00<00:00, 202kB/s]\n",
      "Downloading: 100%|██████████| 111M/111M [12:00<00:00, 162kB/s] \n",
      "Downloading: 100%|██████████| 5.84k/5.84k [00:00<00:00, 16.1MB/s]\n",
      "Downloading: 100%|██████████| 116k/116k [00:00<00:00, 178kB/s]\n",
      "Downloading: 100%|██████████| 153k/153k [00:00<00:00, 239kB/s]\n",
      "Downloading: 100%|██████████| 166k/166k [00:00<00:00, 261kB/s]\n",
      "2025-05-08 05:15:44,668 - modelscope - INFO - initiate model from /home/maojia/.cache/modelscope/hub/iic/speech_eres2net_large_sv_zh-cn_3dspeaker_16k\n",
      "2025-05-08 05:15:44,668 - modelscope - INFO - initiate model from location /home/maojia/.cache/modelscope/hub/iic/speech_eres2net_large_sv_zh-cn_3dspeaker_16k.\n",
      "2025-05-08 05:15:44,669 - modelscope - INFO - initialize model from /home/maojia/.cache/modelscope/hub/iic/speech_eres2net_large_sv_zh-cn_3dspeaker_16k\n",
      "2025-05-08 05:15:44,965 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2025-05-08 05:15:44,966 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2025-05-08 05:15:44,966 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/home/maojia/.cache/modelscope/hub/iic/speech_eres2net_large_sv_zh-cn_3dspeaker_16k'}. trying to build by task and model information.\n",
      "2025-05-08 05:15:44,967 - modelscope - WARNING - No preprocessor key ('eres2net-sv', 'speaker-verification') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.63359, 'text': 'yes'}\n",
      "{'score': 0.08289, 'text': 'no'}\n",
      "{'score': 0.08289, 'text': 'no'}\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "sv_pipline = pipeline(\n",
    "    task='speaker-verification',\n",
    "    model='iic/speech_eres2net_large_sv_zh-cn_3dspeaker_16k',\n",
    "    model_revision='v1.0.0'\n",
    ")\n",
    "speaker1_a_wav = 'https://modelscope.cn/api/v1/models/damo/speech_campplus_sv_zh-cn_16k-common/repo?Revision=master&FilePath=examples/speaker1_a_cn_16k.wav'\n",
    "speaker1_b_wav = 'https://modelscope.cn/api/v1/models/damo/speech_campplus_sv_zh-cn_16k-common/repo?Revision=master&FilePath=examples/speaker1_b_cn_16k.wav'\n",
    "speaker2_a_wav = 'https://modelscope.cn/api/v1/models/damo/speech_campplus_sv_zh-cn_16k-common/repo?Revision=master&FilePath=examples/speaker2_a_cn_16k.wav'\n",
    "# 相同说话人语音\n",
    "result = sv_pipline([speaker1_a_wav, speaker1_b_wav])\n",
    "print(result)\n",
    "# 不同说话人语音\n",
    "result = sv_pipline([speaker1_a_wav, speaker2_a_wav])\n",
    "print(result)\n",
    "# 可以自定义得分阈值来进行识别\n",
    "result = sv_pipline([speaker1_a_wav, speaker2_a_wav], thr=0.262)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb59dd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0002, -0.0012, -0.0009]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sv_pipline.preprocess(\n",
    "    inputs=[speaker1_a_wav, speaker2_a_wav],\n",
    ")\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61585b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2183,  1.0513, -1.0930,  ..., -0.1855, -0.5929,  0.5581],\n",
       "        [ 0.3999, -0.9875, -0.1107,  ...,  0.1198,  1.7506, -0.5841]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = sv_pipline.forward(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b923331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.08289, 'text': 'no'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_pipline.postprocess(\n",
    "    inputs=b,\n",
    "    in_audios=[speaker1_a_wav, speaker2_a_wav],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funasr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
